<!DOCTYPE html>
<html lang = "ru">
<head>
    <meta charset = "UTF-8">
    <title> Нейронные сети </title>
    <link rel="stylesheet" type="text/css" href="style.css"/>
</head>
	<body>
		<div id = header>
			<img src= "image/Логотип.jpg" 
			     alt = "Логотип"
			     height = "115"
			     width = "115"
			     align = "left"
			     hspace = "15"
			     vspace = "5">
			<h2> Описание нейронных сетей. </h2>
			<div id = nav> 
				<a href = "main_page.html"> Описание нейронных сетей </a> <br>
				<a href = "two_page.html"> Как работает нейронная сеть? </a> <br>
				<a href = "sourses.html"> Источники </a>
			</div>
		</div>
		<br>
		<div id = main>
			<br>
			<p> Нейронная сеть — это последовательность нейронов, соединенных между собой синапсами. Структура нейронной сети пришла в мир программирования прямиком из биологии. Благодаря такой структуре, машина обретает способность анализировать и даже запоминать различную информацию. Нейронные сети также способны не только анализировать входящую информацию, но и воспроизводить ее из своей памяти. Другими словами, нейросеть это машинная интерпретация мозга человека, в котором находятся миллионы нейронов передающих информацию в виде электрических импульсов. </p>
			<img src= "image/330px-Neural_network.png" 
			     alt = "Схема простой нейросети"
			     height = "200"
			     width = "300">
			<br><em> Схема простой нейросети. Зелёным цветом <br>обозначены входные нейроны, голубым — <br>скрытые нейроны, жёлтым — выходной нейрон </em>
			<h3>Виды нейронных сетей</h3>
			<table>
              <tr style = "color: RGB(173, 255, 47);">
					<td colspan = 2> По количеству слоёв </td>
					<td colspan = 2> По направлению </td>
					<td colspan = 2> Другие </td>
				</tr>
				<tr style = "color: RGB(0, 247, 0);">
					<td class = cell> Однослойная</td>
					<td> Многослойная</td>
					<td> Прямого распределения</td>
					<td> Реккурентные </td>
					<td> Радиально-базисные функции </td>
					<td> Самоорганизующиеся карты </td>
				</tr>
				<tr style = "color: RGB(30, 185, 30);"> 
					<td> <br>Представляет собой структуру взаимодействия нейронов, в которой сигналы со входного слоя сразу направляются на выходной слой, который, собственно говоря, не только преобразует сигнал, но и сразу же выдаёт ответ. 1-й входной слой только принимает и распределяет сигналы, а нужные вычисления происходят уже во втором слое. Входные нейроны являются объединёнными с основным слоем с помощью синапсов с разными весами, обеспечивающими качество связей. </td>
					<td> <br>Здесь, помимо выходного и входного слоёв, имеются ещё несколько скрытых промежуточных слоёв. Число этих слоёв зависит от степени сложности нейронной сети. Она в большей степени напоминает структуру биологической нейронной сети. Такие виды были разработаны совсем недавно, до этого все процессы были реализованы с помощью однослойных нейронных сетей. Соответствующие решения обладают большими возможностями, если сравнивать с однослойными, ведь в процессе обработки данных каждый промежуточный слой — это промежуточный этап, на котором осуществляется обработка и распределение информации. </td>
					<td> <br>В этой структуре сигнал перемещается строго по направлению от входного слоя к выходному. Движение сигнала в обратном направлении не осуществляется и в принципе невозможно. Сегодня разработки этого плана распространены широко и на сегодняшний день успешно решают задачи распознавания образов, прогнозирования и кластеризации. </td>
					<td> <br>Здесь сигнал двигается и в прямом, и в обратном направлении. В итоге результат выхода способен возвращаться на вход. Выход нейрона определяется весовыми характеристиками и входными сигналами, плюс дополняется предыдущими выходами, снова вернувшимися на вход. Этим нейросетям присуща функция кратковременной памяти, на основании чего сигналы восстанавливаются и дополняются во время их обработки. </td>
					<td> <br>Радиальные базисные функции предоставляют собой гибкий инструмент интерполирования при условии, что множество центров более-менее равномерно покрывает область определения искомой функции (в идеале центры должны быть равноудалены от ближайших соседей). Тем не менее, как правило в промежуточных точках аппроксимация достигает высокой точности только если множество радиальных базисных функций дополнено полиномом, ортогональным к каждой из РБФ. </td>
					<td> <br>Нейронная сеть с обучением без учителя, выполняющая задачу визуализации и кластеризации. Идея сети предложена финским учёным Т. Кохоненом. Является методом проецирования многомерного пространства в пространство с более низкой размерностью (чаще всего, двумерное), применяется также для решения задач моделирования, прогнозирования, выявление наборов независимых признаков, поиска закономерностей в больших массивах данных, разработке компьютерных игр, квантизации цветов к их ограниченному числу индексов в цветовой палитре: при печати на принтере и ранее на ПК или же на приставках с дисплеем с пониженным числом цветов, для архиваторов [общего назначения] или видео-кодеков, и прч. Является одной из версий нейронных сетей Кохонена. </td>
				</tr>
			</table>
			<br>
			<p> Но это далеко не все варианты классификации и виды нейронных сетей. Также их делят: </p>
			<ul>
				<li style = "list-style-image:url(image/пунктМеню.png);"> В зависимости от типов нейронов:
					<ul>
						<li> однородные; </li>
						<li> гибридные. </li>
			    	</ul>
				</li>
				<li style = "list-style-image:url(image/пунктМеню2.png);"> В зависимости от метода нейронных сетей по обучению:
                     <ul>
						<li> обучение с учителем; </li>
						<li> без учителя; </li>
						<li> с подкреплением. </li>
			    	</ul>
				</li>
				<li style = "list-style-image:url(image/пунктМеню3.png);"> По типу входной информации нейронные сети бывают:
                    <ul>
						<li> аналоговые; </li>
						<li> двоичные; </li>
						<li> образные. </li>
			    	</ul>
				</li>
				<li style = "list-style-image:url(image/пунктМеню4.png);"> По характеру настройки синапсов:
                    <ul>
						<li> с фиксированными связями; </li>
						<li> с динамическими связями. </li>
			    	</ul>
				</li>
			</ul>
			<img src= "image/Сверхразум.jpg" 
			     alt = "Сверхразум"
			     height = "350"
			     width = "450">
			<br><em> Когда ты узнал про все виды нейронных сетей </em>
			<h3> Хронология </h3>
			<p> 1943 — У. Маккалок и У. Питтс формализуют понятие нейронной сети в фундаментальной статье о логическом исчислении идей и нервной активности. В начале своего сотрудничества с Питтсом Н. Винер предлагает ему вакуумные лампы в качестве средства для реализации эквивалентов нейронных сетей. </p>
			<p> 1948 — опубликована книга Н. Винера о кибернетике. Основной идеей стало представление сложных биологических процессов математическими моделями. </p>
			<p> 1949 — Д. Хебб предлагает первый алгоритм обучения. </p>
			<p> В 1958 Ф. Розенблатт изобретает однослойный перцептрон и демонстрирует его способность решать задачи классификации. Перцептрон использовали для распознавания образов, прогнозирования погоды. К моменту изобретения перцептрона завершилось расхождение теоретических работ Маккалока с «кибернетикой» Винера; Маккалок и его последователи вышли из состава «Кибернетического клуба». </p>
			<p> В 1960 году Бернард Уидроу совместно со своим студентом Хоффом на основе дельта-правила (формулы Уидроу) разработали Адалин, который сразу начал использоваться для задач предсказания и адаптивного управления. Адалин был построен на базе созданных ими же (Уидроу — Хоффом) новых элементах — мемисторах. </p>
			<p> В 1963 году в Институте проблем передачи информации АН СССР. А. П. Петровым проводится исследование задач «трудных» для перцептрона. На эту работу в области моделирования ИНС в СССР опирался М. М. Бонгарда в своей работе как «сравнительно небольшой переделкой алгоритма (перцептрона) исправить его недостатки». </p>
			<p> В 1969 году М. Минский публикует формальное доказательство ограниченности перцептрона и показывает, что он неспособен решать некоторые задачи (проблема «чётности» и «один в блоке»), связанные с инвариантностью представлений. </p>
			<p> В 1972 году Т. Кохонен и Дж. Андерсон независимо предлагают новый тип нейронных сетей, способных функционировать в качестве памяти.</p>
			<p> В 1973 году Б. В. Хакимов предлагает нелинейную модель с синапсами на основе сплайнов и внедряет её для решения задач в медицине, геологии, экологии. </p>
			<p> 1974 — Пол Дж. Вербос и Галушкин А. И. одновременно изобретают алгоритм обратного распространения ошибки для обучения многослойных перцептронов. </p>
			<p> 1975 — Фукусима представляет когнитрон — самоорганизующуюся сеть, предназначенную для инвариантного распознавания образов, но это достигается только при помощи запоминания практически всех состояний образа. </p>
			<p> 1982 — Дж. Хопфилд показал, что нейронная сеть с обратными связями может представлять собой систему, минимизирующую энергию (сеть Хопфилда). Кохоненом представлены модели сети, обучающейся без учителя (нейронная сеть Кохонена), решающей задачи кластеризации, визуализации данных (самоорганизующаяся карта Кохонена) и другие задачи предварительного анализа данных. </p>
			<p> 1986 — Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом, а так же независимо и одновременно С. И. Барцевым и В. А. Охониным переоткрыт и развит метод обратного распространения ошибки. </p>
			<p> 2007 — Джеффри Хинтоном в университете Торонто созданы алгоритмы глубокого обучения многослойных нейронных сетей. Хинтон при обучении нижних слоёв сети использовал ограниченную машину Больцмана (RBM — Restricted Boltzmann Machine). По Хинтону необходимо использовать много примеров распознаваемых образов (например, множество лиц людей на разных фонах). После обучения получается готовое быстро работающее приложение, способное решать конкретную задачу (например, осуществлять поиск лиц на изображении). </p>
		</main>
		<br>
		<br>
		<br>
		<div id = footer class = "its_footer">
			<p>Это подвал.</p>
		</div>
	</body>
</html> 